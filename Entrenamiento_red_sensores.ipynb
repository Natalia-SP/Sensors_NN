{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 150, 12) (140, 1)\n",
      "(60, 150, 12) (60, 1)\n",
      "(140, 150, 12) (140, 2) (60, 150, 12) (60, 2)\n",
      "&gt;#1: 76.667\n",
      "&gt;#2: 85.000\n",
      "&gt;#3: 70.000\n",
      "&gt;#4: 70.000\n",
      "&gt;#5: 73.333\n",
      "&gt;#6: 81.667\n",
      "&gt;#7: 71.667\n",
      "&gt;#8: 71.667\n",
      "&gt;#9: 63.333\n",
      "&gt;#10: 73.333\n",
      "[76.66666507720947, 85.00000238418579, 69.9999988079071, 69.9999988079071, 73.33333492279053, 81.66666626930237, 71.66666388511658, 71.66666388511658, 63.333332538604736, 73.33333492279053]\n",
      "Accuracy: 73.667% (+/-5.859)\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento.py\n",
    "# convlstm model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "\n",
    "# Carga un solo archivo como una matriz numpy\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "# carga una lista de archivos y regresa como una matriz numérica 3d\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # apila un grupo para que las características sean de 3 dimensiones\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# carga el dataset de un grupo, entrenamiento o prueba\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # carga todos los archivos como un arreglo\n",
    "    filenames = list()\n",
    "    # aceleración sensor 1\n",
    "    filenames += ['acc_x_1_'+group+'.txt', 'acc_y_1_'+group+'.txt', 'acc_z_1_'+group+'.txt']\n",
    "    # giroscopio sensor 1\n",
    "    filenames += ['gyro_x_1_'+group+'.txt', 'gyro_y_1_'+group+'.txt', 'gyro_z_1_'+group+'.txt']\n",
    "    # aceleración sensor 2\n",
    "    filenames += ['acc_x_2_'+group+'.txt', 'acc_y_2_'+group+'.txt', 'acc_z_2_'+group+'.txt']\n",
    "    # giroscopio sensor 2\n",
    "    filenames += ['gyro_x_2_'+group+'.txt', 'gyro_y_2_'+group+'.txt', 'gyro_z_2_'+group+'.txt']\n",
    "    # carga los datos de entrada\n",
    "    X = load_group(filenames, filepath)\n",
    "    # carga las clases de salida\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "# carga los datasets, devuelve datos y etiquetas de entrenamiento y prueba\n",
    "def load_dataset(prefix=''):\n",
    "    # carga todo el entrenamiento\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'SensorDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # carga todo el test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'SensorDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # valores de clase de compensación cero\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # codificación one hot en y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# entrena y evalua el modelo\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape en subsecuencias (muestras, pasos de tiempo, filas, columnas, canales)\n",
    "    n_steps, n_length = 10, 15\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    # define modelo\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # entrena la red\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    now = datetime.now()\n",
    "    model.save('convlstm_sensors'+now.strftime(\" %d-%m-%Y %H-%M-%S\")+'.h5')\n",
    "    # evalua modelo\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "# resumir puntuaciones\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Precisión: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "# correr un experimento (10 veces)\n",
    "def run_experiment(repeats=10):\n",
    "    # cargar los datos\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repetir experimento\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('Exp-#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # resumen de resultados\n",
    "    summarize_results(scores)\n",
    "\n",
    "# correr un experimento\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actumlogos-gpu",
   "language": "python",
   "name": "actumlogos-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
