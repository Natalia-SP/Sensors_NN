{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "import keras.models\n",
    "# from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Carga un solo archivo como una matriz numpy\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "# carga una lista de archivos y regresa como una matriz numérica 3d\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # apila un grupo para que las características sean de 3 dimensiones\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# carga el dataset de un grupo, entrenamiento o prueba\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # carga todos los archivos como un arreglo\n",
    "    filenames = list()\n",
    "    # aceleración sensor 1\n",
    "    filenames += ['acc_x_1_'+group+'.txt', 'acc_y_1_'+group+'.txt', 'acc_z_1_'+group+'.txt']\n",
    "    # giroscopio sensor 1\n",
    "    filenames += ['gyro_x_1_'+group+'.txt', 'gyro_y_1_'+group+'.txt', 'gyro_z_1_'+group+'.txt']\n",
    "    # aceleración sensor 2\n",
    "    filenames += ['acc_x_2_'+group+'.txt', 'acc_y_2_'+group+'.txt', 'acc_z_2_'+group+'.txt']\n",
    "    # giroscopio sensor 2\n",
    "    filenames += ['gyro_x_2_'+group+'.txt', 'gyro_y_2_'+group+'.txt', 'gyro_z_2_'+group+'.txt']\n",
    "    # carga los datos de entrada\n",
    "    X = load_group(filenames, filepath)\n",
    "    # carga las clases de salida\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "# carga los datasets, devuelve datos y etiquetas de entrenamiento y prueba\n",
    "def load_dataset(prefix=''):\n",
    "    # carga todo el entrenamiento\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'SensorDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # carga todo el test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'SensorDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # valores de clase de compensación cero\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # codificación one hot en y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "def test(trainX, trainy, testX, testy,path='convlstm_sensors'):\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape en subsecuencias (muestras, pasos de tiempo, filas, columnas, canales)\n",
    "    n_steps, n_length = 10, 15\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    model = keras.models.load_model(path+'.h5')\n",
    "    # evaluar modelo\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    test_preds = np.argmax(model.predict(testX), axis=-1) # 0 significa aceptado, 1 rechazado\n",
    "    return accuracy, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy, testX, testy = load_dataset()\n",
    "score, pred = test(trainX, trainy, testX, testy)\n",
    "score * 100.0 , pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "actumlogos-gpu",
   "language": "python",
   "name": "actumlogos-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
